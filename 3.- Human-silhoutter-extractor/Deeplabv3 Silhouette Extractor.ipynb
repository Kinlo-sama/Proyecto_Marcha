{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import cv2\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.6.0\" to /home/kinlo/.cache/torch/hub/v0.6.0.zip\n",
      "/home/kinlo/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/kinlo/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth\" to /home/kinlo/.cache/torch/hub/checkpoints/deeplabv3_resnet101_coco-586e9e4e.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been loaded.\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'deeplabv3_resnet101', pretrained = True)\n",
    "people_class = 15\n",
    "\n",
    "model.eval()\n",
    "print(\"Model has been loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = torch.FloatTensor([[[[1.0, 2.0, 1.0],[2.0, 4.0, 2.0],[1.0, 2.0, 1.0]]]]) / 16.0\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "    blur = blur.to('cuda')\n",
    "\n",
    "# Apply preprocessing (normalization)\n",
    "preprocess = transforms.Compose([\n",
    "\ttransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to create segmentation mask\n",
    "def makeSegMask(img):\n",
    "    # Scale input frame\n",
    "\tframe_data = torch.FloatTensor( img ) / 255.0\n",
    "\n",
    "\tinput_tensor = preprocess(frame_data.permute(2, 0, 1))\n",
    "    \n",
    "    # Create mini-batch to be used by the model\n",
    "\tinput_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "    # Use GPU if supported, for better performance\n",
    "\tif torch.cuda.is_available():\n",
    "\t\tinput_batch = input_batch.to('cuda')\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\toutput = model(input_batch)['out'][0]\n",
    "\n",
    "\tsegmentation = output.argmax(0)\n",
    "\n",
    "\tbgOut = output[0:1][:][:]\n",
    "\ta = (1.0 - F.relu(torch.tanh(bgOut * 0.30 - 1.0))).pow(0.5) * 2.0\n",
    "\n",
    "\tpeople = segmentation.eq( torch.ones_like(segmentation).long().fill_(people_class) ).float()\n",
    "\n",
    "\tpeople.unsqueeze_(0).unsqueeze_(0)\n",
    "\t\n",
    "\tfor i in range(3):\n",
    "\t\tpeople = F.conv2d(people, blur, stride=1, padding=1)\n",
    "\n",
    "\t# Activation function to combine masks - F.hardtanh(a * b)\n",
    "\tcombined_mask = F.relu(F.hardtanh(a * (people.squeeze().pow(1.5)) ))\n",
    "\tcombined_mask = combined_mask.expand(1, 3, -1, -1)\n",
    "\n",
    "\tres = (combined_mask * 255.0).cpu().squeeze().byte().permute(1, 2, 0).numpy()\n",
    "\n",
    "\treturn res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('../Persona8/persona8_9_f.webm')\n",
    "\n",
    "# Get video file's dimensions\n",
    "frame_width = int(video.get(3))\n",
    "frame_height = int(video.get(4))\n",
    "\n",
    "# Creates output video file\n",
    "out = cv2.VideoWriter('Persona_fcn.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 30, (frame_width,frame_height))\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "while (video.isOpened):\n",
    "    # Read each frame one by one\n",
    "    success, img = video.read()\n",
    "    \n",
    "    # Run if there are still frames left\n",
    "    if (success):\n",
    "        img_resized = cv2.resize(img, (256, 256))\n",
    "        # Apply background subtraction to extract foreground (silhouette)\n",
    "        mask = makeSegMask(img_resized)\n",
    "        \n",
    "        # Apply thresholding to convert mask to binary map\n",
    "        ret,thresh = cv2.threshold(mask,127,255,cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Write processed frame to output file\n",
    "        \n",
    "        # cv2.rectangle(mask, (10, 2), (100,20), (255,255,255), -1)\n",
    "        # cv2.putText(mask, fps, (15, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5 , (0,0,0))\n",
    "        \n",
    "        # Show extracted silhouette only, by multiplying mask and input frame\n",
    "        #final = cv2.bitwise_and(thresh, img_resized)\n",
    "        \n",
    "        # Show current frame\n",
    "        cv2.imshow('Silhouette Mask', mask)\n",
    "        #cv2.imshow('Extracted Silhouette', final)\n",
    "        out.write(mask)\n",
    "        # Allow early termination with Esc key\n",
    "        key = cv2.waitKey(10)\n",
    "        if key == 27:\n",
    "            break\n",
    "    # Break when there are no more frames  \n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
